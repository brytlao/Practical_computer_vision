{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAPTER_10_Machine Learning for Computer Vision",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brytlao/Practical_computer_vision/blob/master/CHAPTER_10_Machine_Learning_for_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "04_Qrax6p66-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Chapter 10: Machine Learning for Computer Vision**"
      ]
    },
    {
      "metadata": {
        "id": "neh7nIVDqBtv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tackles basic topis on machine learning. Has examples for computer vision."
      ]
    },
    {
      "metadata": {
        "id": "OoRVCvV2qUgE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Concepts in machine learning**"
      ]
    },
    {
      "metadata": {
        "id": "KOuL9ykDqZv1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*   Supervised learning\n",
        "*   Classification\n",
        "*   Regression\n",
        "*   Unsupervised learning\n",
        "*   Curse of dimensionality\n",
        "*   Optimization\n",
        "*   Preprocessing\n",
        "*   Normalization\n",
        "*   Noise\n",
        "*   Postprocessing\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fx3luCSaqjtU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "metadata": {
        "id": "Jr-fLevus1yb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Assuming A is being evaluated:\n",
        "*   True positive (TP): actual A, predicted A\n",
        "*   True negative (TN): actual B, predicted B\n",
        "*   False positive (FP): actual B, predicted A\n",
        "*   False negative (FN): actual A, predicted B"
      ]
    },
    {
      "metadata": {
        "id": "aY2HohQXZ5k3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Examples below assume:\n",
        "*   2 classes: 0, 1\n",
        "*   wrt class 0: TP = 1, TN = 2,  FP = 3, FN = 4"
      ]
    },
    {
      "metadata": {
        "id": "54B5_2wICthF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Accuracy**"
      ]
    },
    {
      "metadata": {
        "id": "W1fh-tjACwqY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Proportion of correct classifications from overall number of cases"
      ]
    },
    {
      "metadata": {
        "id": "C2p2wy7VDB8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$Accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$"
      ]
    },
    {
      "metadata": {
        "id": "OJS0JeL9C1K4",
        "colab_type": "code",
        "outputId": "51614b6a-8948-4f42-8d1c-046c0f31592c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "true_y = np.array([0,1,1,1,1,1,0,0,0,0]) # ground truth\n",
        "pred_y = np.array([0,1,1,0,0,0,1,1,1,1]) # prediction\n",
        "\n",
        "accuracy = accuracy_score(true_y,pred_y)\n",
        "print(\"ground truth: {}\".format(true_y))\n",
        "print(\"prediction: {}\".format(pred_y))\n",
        "print(\"precision: {}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ground truth: [1 2 3 2 3 3 1 2 2]\n",
            "prediction: [2 2 1 2 1 3 2 3 2]\n",
            "precision: 0.4444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ghJJb6tqooW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Precision**"
      ]
    },
    {
      "metadata": {
        "id": "WczHmtUMwZGY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Proportion of correct positive classifications from cases that are predicted as positive"
      ]
    },
    {
      "metadata": {
        "id": "juMq5FoytVKn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$Precision=\\frac{TP}{TP+FP}$"
      ]
    },
    {
      "metadata": {
        "id": "gsQejXYitd8g",
        "colab_type": "code",
        "outputId": "a3b70d18-bd18-4dd5-ac57-c9fab080df95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "import numpy as np\n",
        "\n",
        "true_y = np.array([0,1,1,1,1,1,0,0,0,0]) # ground truth\n",
        "pred_y = np.array([0,1,1,0,0,0,1,1,1,1]) # prediction\n",
        "\n",
        "precision = precision_score(true_y,pred_y,average='macro')\n",
        "print(\"ground truth: {}\".format(true_y))\n",
        "print(\"prediction: {}\".format(pred_y))\n",
        "print(\"precision: {}\".format(precision))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ground truth: [0 1 1 1 1 1 0 0 0 0]\n",
            "prediction: [0 1 1 0 0 0 1 1 1 1]\n",
            "precision: 0.29166666666666663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ZWPJuUOqxNN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Recall**"
      ]
    },
    {
      "metadata": {
        "id": "kbY7x385wdKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Proportion of correct positive classifications from cases that are actually positive"
      ]
    },
    {
      "metadata": {
        "id": "dHBCysvmu8Ee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$Recall=\\frac{TP}{TP+FN}$"
      ]
    },
    {
      "metadata": {
        "id": "INLgmhiMwlLw",
        "colab_type": "code",
        "outputId": "acfd9177-fbc1-4957-ff25-b42b3ffc58e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "\n",
        "true_y = np.array([0,1,1,1,1,1,0,0,0,0]) # ground truth\n",
        "pred_y = np.array([0,1,1,0,0,0,1,1,1,1]) # prediction\n",
        "\n",
        "recall = recall_score(true_y,pred_y,average='macro')\n",
        "print(\"ground truth: {}\".format(true_y))\n",
        "print(\"prediction: {}\".format(pred_y))\n",
        "print(\"precision: {}\".format(recall))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ground truth: [0 1 1 1 1 1 0 0 0 0]\n",
            "prediction: [0 1 1 0 0 0 1 1 1 1]\n",
            "precision: 0.30000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GkhftGHlqzYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**F-measure**"
      ]
    },
    {
      "metadata": {
        "id": "PsQ9N_Ks3vdR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Measure of test accuracy"
      ]
    },
    {
      "metadata": {
        "id": "WeBhc27I39Gp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$F_1 =2\\cdot\\frac{precision \\cdot recall}{precision + recall}$"
      ]
    },
    {
      "metadata": {
        "id": "aHpa0BuMp3n6",
        "colab_type": "code",
        "outputId": "3b3686a5-51ab-413d-83d0-6d5115909185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "true_y = np.array([0,1,1,1,1,1,0,0,0,0]) # ground truth\n",
        "pred_y = np.array([0,1,1,0,0,0,1,1,1,1]) # prediction\n",
        "\n",
        "f1_score = f1_score(true_y,pred_y,average='macro')\n",
        "print(\"ground truth: {}\".format(true_y))\n",
        "print(\"prediction: {}\".format(pred_y))\n",
        "print(\"precision: {}\".format(f1_score))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ground truth: [0 1 1 1 1 1 0 0 0 0]\n",
            "prediction: [0 1 1 0 0 0 1 1 1 1]\n",
            "precision: 0.29292929292929293\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}